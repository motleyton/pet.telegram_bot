{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:07.551423Z",
     "iopub.status.busy": "2022-07-24T13:40:07.550971Z",
     "iopub.status.idle": "2022-07-24T13:40:07.576331Z",
     "shell.execute_reply": "2022-07-24T13:40:07.575491Z",
     "shell.execute_reply.started": "2022-07-24T13:40:07.551343Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:07.578553Z",
     "iopub.status.busy": "2022-07-24T13:40:07.578218Z",
     "iopub.status.idle": "2022-07-24T13:40:10.416047Z",
     "shell.execute_reply": "2022-07-24T13:40:10.414930Z",
     "shell.execute_reply.started": "2022-07-24T13:40:07.578518Z"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '../input/bashim-quotes/dataset.jsonl'\n",
    "with open(DATASET_PATH) as f: \n",
    "    df = pd.read_json(DATASET_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:10.417935Z",
     "iopub.status.busy": "2022-07-24T13:40:10.417588Z",
     "iopub.status.idle": "2022-07-24T13:40:10.424886Z",
     "shell.execute_reply": "2022-07-24T13:40:10.423451Z",
     "shell.execute_reply.started": "2022-07-24T13:40:10.417900Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:10.429662Z",
     "iopub.status.busy": "2022-07-24T13:40:10.428274Z",
     "iopub.status.idle": "2022-07-24T13:40:10.437417Z",
     "shell.execute_reply": "2022-07-24T13:40:10.436227Z",
     "shell.execute_reply.started": "2022-07-24T13:40:10.429622Z"
    }
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:10.439987Z",
     "iopub.status.busy": "2022-07-24T13:40:10.439691Z",
     "iopub.status.idle": "2022-07-24T13:40:10.448280Z",
     "shell.execute_reply": "2022-07-24T13:40:10.446707Z",
     "shell.execute_reply.started": "2022-07-24T13:40:10.439954Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_text_files(data_json, dest_path):\n",
    "    f = open(dest_path, 'w')\n",
    "    data = ''\n",
    "    for texts in data_json:\n",
    "        summary = str(texts)\n",
    "        data += summary + '\\n'\n",
    "    f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:10.450619Z",
     "iopub.status.busy": "2022-07-24T13:40:10.449602Z",
     "iopub.status.idle": "2022-07-24T13:40:10.847887Z",
     "shell.execute_reply": "2022-07-24T13:40:10.846710Z",
     "shell.execute_reply.started": "2022-07-24T13:40:10.450583Z"
    }
   },
   "outputs": [],
   "source": [
    "build_text_files(df,'train_dataset.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:10.849875Z",
     "iopub.status.busy": "2022-07-24T13:40:10.849266Z",
     "iopub.status.idle": "2022-07-24T13:40:19.414791Z",
     "shell.execute_reply": "2022-07-24T13:40:19.413767Z",
     "shell.execute_reply.started": "2022-07-24T13:40:10.849810Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:19.416563Z",
     "iopub.status.busy": "2022-07-24T13:40:19.416185Z",
     "iopub.status.idle": "2022-07-24T13:40:19.423771Z",
     "shell.execute_reply": "2022-07-24T13:40:19.421378Z",
     "shell.execute_reply.started": "2022-07-24T13:40:19.416515Z"
    }
   },
   "outputs": [],
   "source": [
    "train_path = 'train_dataset.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:40:19.428073Z",
     "iopub.status.busy": "2022-07-24T13:40:19.426771Z",
     "iopub.status.idle": "2022-07-24T13:41:08.161807Z",
     "shell.execute_reply": "2022-07-24T13:41:08.160859Z",
     "shell.execute_reply.started": "2022-07-24T13:40:19.428036Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(data, tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset, data_collator\n",
    "\n",
    "train_dataset, data_collator = load_dataset(train_path, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:41:08.164253Z",
     "iopub.status.busy": "2022-07-24T13:41:08.163402Z",
     "iopub.status.idle": "2022-07-24T13:41:08.229127Z",
     "shell.execute_reply": "2022-07-24T13:41:08.228012Z",
     "shell.execute_reply.started": "2022-07-24T13:41:08.164216Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:41:08.231898Z",
     "iopub.status.busy": "2022-07-24T13:41:08.230713Z",
     "iopub.status.idle": "2022-07-24T13:41:47.602896Z",
     "shell.execute_reply": "2022-07-24T13:41:47.601767Z",
     "shell.execute_reply.started": "2022-07-24T13:41:08.231858Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"sberbank-ai/rugpt3small_based_on_gpt2\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:41:47.605295Z",
     "iopub.status.busy": "2022-07-24T13:41:47.604537Z",
     "iopub.status.idle": "2022-07-24T13:41:47.616301Z",
     "shell.execute_reply": "2022-07-24T13:41:47.615354Z",
     "shell.execute_reply.started": "2022-07-24T13:41:47.605254Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-chief\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=4, # batch size for training\n",
    "    per_device_eval_batch_size=4,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved\n",
    "    warmup_steps=200,# number of warmup steps for learning rate scheduler\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:41:47.619743Z",
     "iopub.status.busy": "2022-07-24T13:41:47.619471Z",
     "iopub.status.idle": "2022-07-24T13:41:49.558950Z",
     "shell.execute_reply": "2022-07-24T13:41:49.557510Z",
     "shell.execute_reply.started": "2022-07-24T13:41:47.619718Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:41:49.560880Z",
     "iopub.status.busy": "2022-07-24T13:41:49.560533Z",
     "iopub.status.idle": "2022-07-24T13:41:49.599704Z",
     "shell.execute_reply": "2022-07-24T13:41:49.598593Z",
     "shell.execute_reply.started": "2022-07-24T13:41:49.560829Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset[:5000],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:49:25.883690Z",
     "iopub.status.busy": "2022-07-24T13:49:25.883313Z",
     "iopub.status.idle": "2022-07-24T13:56:25.753665Z",
     "shell.execute_reply": "2022-07-24T13:56:25.752808Z",
     "shell.execute_reply.started": "2022-07-24T13:49:25.883661Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:56:58.325388Z",
     "iopub.status.busy": "2022-07-24T13:56:58.324794Z",
     "iopub.status.idle": "2022-07-24T13:56:59.548299Z",
     "shell.execute_reply": "2022-07-24T13:56:59.547334Z",
     "shell.execute_reply.started": "2022-07-24T13:56:58.325353Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.save_model('model_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:57:00.719567Z",
     "iopub.status.busy": "2022-07-24T13:57:00.718899Z",
     "iopub.status.idle": "2022-07-24T13:57:00.884515Z",
     "shell.execute_reply": "2022-07-24T13:57:00.883591Z",
     "shell.execute_reply.started": "2022-07-24T13:57:00.719531Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('tokenizer_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-24T13:57:09.920469Z",
     "iopub.status.busy": "2022-07-24T13:57:09.920113Z",
     "iopub.status.idle": "2022-07-24T13:57:11.504807Z",
     "shell.execute_reply": "2022-07-24T13:57:11.503775Z",
     "shell.execute_reply.started": "2022-07-24T13:57:09.920440Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('tokenizer_chat')\n",
    "model.save_pretrained('model_chat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T13:49:16.088975Z",
     "iopub.status.idle": "2022-07-24T13:49:16.089443Z",
     "shell.execute_reply": "2022-07-24T13:49:16.089222Z",
     "shell.execute_reply.started": "2022-07-24T13:49:16.089199Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer_for_dialogue = AutoTokenizer.from_pretrained(\"tokenizer_chat\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T13:49:16.091670Z",
     "iopub.status.idle": "2022-07-24T13:49:16.092778Z",
     "shell.execute_reply": "2022-07-24T13:49:16.092524Z",
     "shell.execute_reply.started": "2022-07-24T13:49:16.092500Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_chat.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T13:49:16.094140Z",
     "iopub.status.idle": "2022-07-24T13:49:16.095257Z",
     "shell.execute_reply": "2022-07-24T13:49:16.095028Z",
     "shell.execute_reply.started": "2022-07-24T13:49:16.094976Z"
    }
   },
   "outputs": [],
   "source": [
    "tokens = tokenizer(prefix, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T13:49:16.096558Z",
     "iopub.status.idle": "2022-07-24T13:49:16.097414Z",
     "shell.execute_reply": "2022-07-24T13:49:16.097174Z",
     "shell.execute_reply.started": "2022-07-24T13:49:16.097151Z"
    }
   },
   "outputs": [],
   "source": [
    "def respond_to_dialog(texts):\n",
    "    prefix = '\\nx:'\n",
    "    for i, t in enumerate(texts):\n",
    "        prefix += t\n",
    "        prefix += '\\nx:' if i % 2 == 1 else '\\ny:'\n",
    "    tokens = tokenizer(prefix, return_tensors='pt')\n",
    "    tokens = {k: v.to(model.device) for k, v in tokens.items()}\n",
    "    end_token_id = tokenizer.encode('\\n')[0]\n",
    "    size = tokens['input_ids'].shape[1]\n",
    "    output = model.generate(\n",
    "        **tokens, \n",
    "        eos_token_id=end_token_id,\n",
    "        do_sample=True, \n",
    "        max_length=size+128, \n",
    "        repetition_penalty=3.2, \n",
    "        temperature=1,\n",
    "        num_beams=3,\n",
    "        length_penalty=0.01,\n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    decoded = tokenizer.decode(output[0])\n",
    "    result = decoded[len(prefix):]\n",
    "    return result.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-07-24T13:49:16.098997Z",
     "iopub.status.idle": "2022-07-24T13:49:16.099623Z",
     "shell.execute_reply": "2022-07-24T13:49:16.099385Z",
     "shell.execute_reply.started": "2022-07-24T13:49:16.099359Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = input('Начните диалог с ботом любой фразой\\n')\n",
    "history = [seed]\n",
    "while True:\n",
    "    result = respond_to_dialog(history[-10:])\n",
    "    next_sentence = input(result + '\\n')\n",
    "    history.append(result)\n",
    "    history.append(next_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
